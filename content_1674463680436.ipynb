{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXkRVjkgnrje",
        "outputId": "6b807a84-7d75-4949-dc10-263d9fb667a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Sep 12 12:36:25 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_89S9nweVVM0",
        "outputId": "8fe4f216-e303-4d77-baea-d25d65b52117"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#load drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUCApbiHg0D9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import shutil\n",
        "import cv2\n",
        "\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.optimizer_v2.adam import Adam\n",
        "from keras.layers import concatenate\n",
        "from keras.layers import BatchNormalization \n",
        "from keras.layers import Activation\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import Input\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Dropout\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from albumentations import *\n",
        "from keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBPiAIHWtkZQ",
        "outputId": "1520e543-ce5a-4830-cb89-9736522582f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.8.2\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "B7zoLpJog76n",
        "outputId": "63751606-bcc2-44b7-def3-a93772724c23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 240, 240, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 240, 240, 16  160         ['input_3[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 240, 240, 16  64         ['conv2d_38[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 240, 240, 16  0           ['batch_normalization_36[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 240, 240, 16  2320        ['activation_36[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 240, 240, 16  64         ['conv2d_39[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 240, 240, 16  0           ['batch_normalization_37[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_8 (MaxPooling2D)  (None, 120, 120, 16  0          ['activation_37[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_16 (Dropout)           (None, 120, 120, 16  0           ['max_pooling2d_8[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 120, 120, 32  4640        ['dropout_16[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 120, 120, 32  128        ['conv2d_40[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 120, 120, 32  0           ['batch_normalization_38[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 120, 120, 32  9248        ['activation_38[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 120, 120, 32  128        ['conv2d_41[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 120, 120, 32  0           ['batch_normalization_39[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_9 (MaxPooling2D)  (None, 60, 60, 32)  0           ['activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_17 (Dropout)           (None, 60, 60, 32)   0           ['max_pooling2d_9[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 60, 60, 64)   18496       ['dropout_17[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 60, 60, 64)  256         ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 60, 60, 64)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 60, 60, 64)   36928       ['activation_40[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 60, 60, 64)  256         ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 60, 60, 64)   0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_10 (MaxPooling2D  (None, 30, 30, 64)  0           ['activation_41[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dropout_18 (Dropout)           (None, 30, 30, 64)   0           ['max_pooling2d_10[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 30, 30, 128)  73856       ['dropout_18[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 30, 30, 128)  512        ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 30, 30, 128)  0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 30, 30, 128)  147584      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 30, 30, 128)  512        ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 30, 30, 128)  0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_11 (MaxPooling2D  (None, 15, 15, 128)  0          ['activation_43[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dropout_19 (Dropout)           (None, 15, 15, 128)  0           ['max_pooling2d_11[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 15, 15, 256)  295168      ['dropout_19[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 15, 15, 256)  0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 15, 15, 256)  590080      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 15, 15, 256)  0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_8 (Conv2DTran  (None, 30, 30, 128)  295040     ['activation_45[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate)    (None, 30, 30, 256)  0           ['conv2d_transpose_8[0][0]',     \n",
            "                                                                  'activation_43[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_20 (Dropout)           (None, 30, 30, 256)  0           ['concatenate_8[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 30, 30, 128)  295040      ['dropout_20[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 30, 30, 128)  512        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 30, 30, 128)  0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 30, 30, 128)  147584      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 30, 30, 128)  512        ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 30, 30, 128)  0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_9 (Conv2DTran  (None, 60, 60, 64)  73792       ['activation_47[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate)    (None, 60, 60, 128)  0           ['conv2d_transpose_9[0][0]',     \n",
            "                                                                  'activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_21 (Dropout)           (None, 60, 60, 128)  0           ['concatenate_9[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 60, 60, 64)   73792       ['dropout_21[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 60, 60, 64)  256         ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 60, 60, 64)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 60, 60, 64)   36928       ['activation_48[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 60, 60, 64)  256         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 60, 60, 64)   0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_10 (Conv2DTra  (None, 120, 120, 32  18464      ['activation_49[0][0]']          \n",
            " nspose)                        )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenate)   (None, 120, 120, 64  0           ['conv2d_transpose_10[0][0]',    \n",
            "                                )                                 'activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_22 (Dropout)           (None, 120, 120, 64  0           ['concatenate_10[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 120, 120, 32  18464       ['dropout_22[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 120, 120, 32  128        ['conv2d_52[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 120, 120, 32  0           ['batch_normalization_50[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 120, 120, 32  9248        ['activation_50[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 120, 120, 32  128        ['conv2d_53[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 120, 120, 32  0           ['batch_normalization_51[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_11 (Conv2DTra  (None, 240, 240, 16  4624       ['activation_51[0][0]']          \n",
            " nspose)                        )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenate)   (None, 240, 240, 32  0           ['conv2d_transpose_11[0][0]',    \n",
            "                                )                                 'activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_23 (Dropout)           (None, 240, 240, 32  0           ['concatenate_11[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 240, 240, 16  4624        ['dropout_23[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 240, 240, 16  64         ['conv2d_54[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 240, 240, 16  0           ['batch_normalization_52[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 240, 240, 16  2320        ['activation_52[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 240, 240, 16  64         ['conv2d_55[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 240, 240, 16  0           ['batch_normalization_53[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 240, 240, 1)  17          ['activation_53[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,164,305\n",
            "Trainable params: 2,161,361\n",
            "Non-trainable params: 2,944\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.1763 - dice_score: 0.1578\n",
            "Epoch 1: val_loss improved from inf to 0.57358, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 55s 356ms/step - loss: 0.1763 - dice_score: 0.1578 - val_loss: 0.5736 - val_dice_score: 0.0430 - lr: 0.0020\n",
            "Epoch 2/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0453 - dice_score: 0.6555\n",
            "Epoch 2: val_loss improved from 0.57358 to 0.43670, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 345ms/step - loss: 0.0453 - dice_score: 0.6555 - val_loss: 0.4367 - val_dice_score: 0.2403 - lr: 0.0020\n",
            "Epoch 3/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0255 - dice_score: 0.7283\n",
            "Epoch 3: val_loss improved from 0.43670 to 0.02791, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 347ms/step - loss: 0.0255 - dice_score: 0.7283 - val_loss: 0.0279 - val_dice_score: 0.6145 - lr: 0.0020\n",
            "Epoch 4/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0191 - dice_score: 0.7471\n",
            "Epoch 4: val_loss improved from 0.02791 to 0.02213, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 345ms/step - loss: 0.0191 - dice_score: 0.7471 - val_loss: 0.0221 - val_dice_score: 0.6249 - lr: 0.0020\n",
            "Epoch 5/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0169 - dice_score: 0.7508\n",
            "Epoch 5: val_loss did not improve from 0.02213\n",
            "147/147 [==============================] - 50s 344ms/step - loss: 0.0169 - dice_score: 0.7508 - val_loss: 0.0256 - val_dice_score: 0.8220 - lr: 0.0020\n",
            "Epoch 6/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0146 - dice_score: 0.7683\n",
            "Epoch 6: val_loss did not improve from 0.02213\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0146 - dice_score: 0.7683 - val_loss: 0.0238 - val_dice_score: 0.5714 - lr: 0.0020\n",
            "Epoch 7/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0137 - dice_score: 0.7728\n",
            "Epoch 7: val_loss improved from 0.02213 to 0.01381, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 346ms/step - loss: 0.0137 - dice_score: 0.7728 - val_loss: 0.0138 - val_dice_score: 0.7608 - lr: 0.0020\n",
            "Epoch 8/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0128 - dice_score: 0.7765\n",
            "Epoch 8: val_loss did not improve from 0.01381\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0128 - dice_score: 0.7765 - val_loss: 0.0364 - val_dice_score: 0.7679 - lr: 0.0020\n",
            "Epoch 9/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0118 - dice_score: 0.7908\n",
            "Epoch 9: val_loss did not improve from 0.01381\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0118 - dice_score: 0.7908 - val_loss: 0.0148 - val_dice_score: 0.7155 - lr: 0.0020\n",
            "Epoch 10/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0114 - dice_score: 0.7992\n",
            "Epoch 10: val_loss improved from 0.01381 to 0.01262, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 346ms/step - loss: 0.0114 - dice_score: 0.7992 - val_loss: 0.0126 - val_dice_score: 0.8615 - lr: 0.0020\n",
            "Epoch 11/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0111 - dice_score: 0.8008\n",
            "Epoch 11: val_loss did not improve from 0.01262\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0111 - dice_score: 0.8008 - val_loss: 0.0128 - val_dice_score: 0.7501 - lr: 0.0020\n",
            "Epoch 12/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0106 - dice_score: 0.8035\n",
            "Epoch 12: val_loss improved from 0.01262 to 0.01089, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 346ms/step - loss: 0.0106 - dice_score: 0.8035 - val_loss: 0.0109 - val_dice_score: 0.7936 - lr: 0.0020\n",
            "Epoch 13/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0102 - dice_score: 0.8070\n",
            "Epoch 13: val_loss improved from 0.01089 to 0.01059, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 346ms/step - loss: 0.0102 - dice_score: 0.8070 - val_loss: 0.0106 - val_dice_score: 0.7772 - lr: 0.0020\n",
            "Epoch 14/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0097 - dice_score: 0.8168\n",
            "Epoch 14: val_loss did not improve from 0.01059\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0097 - dice_score: 0.8168 - val_loss: 0.0110 - val_dice_score: 0.8502 - lr: 0.0020\n",
            "Epoch 15/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0095 - dice_score: 0.8214\n",
            "Epoch 15: val_loss did not improve from 0.01059\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0095 - dice_score: 0.8214 - val_loss: 0.0130 - val_dice_score: 0.7554 - lr: 0.0020\n",
            "Epoch 16/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0094 - dice_score: 0.8236\n",
            "Epoch 16: val_loss improved from 0.01059 to 0.01049, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 345ms/step - loss: 0.0094 - dice_score: 0.8236 - val_loss: 0.0105 - val_dice_score: 0.8009 - lr: 0.0020\n",
            "Epoch 17/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0090 - dice_score: 0.8307\n",
            "Epoch 17: val_loss improved from 0.01049 to 0.00984, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 345ms/step - loss: 0.0090 - dice_score: 0.8307 - val_loss: 0.0098 - val_dice_score: 0.8027 - lr: 0.0020\n",
            "Epoch 18/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0091 - dice_score: 0.8300\n",
            "Epoch 18: val_loss did not improve from 0.00984\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0091 - dice_score: 0.8300 - val_loss: 0.0111 - val_dice_score: 0.7728 - lr: 0.0020\n",
            "Epoch 19/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0089 - dice_score: 0.8291\n",
            "Epoch 19: val_loss did not improve from 0.00984\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0089 - dice_score: 0.8291 - val_loss: 0.0189 - val_dice_score: 0.8510 - lr: 0.0020\n",
            "Epoch 20/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0086 - dice_score: 0.8356\n",
            "Epoch 20: val_loss improved from 0.00984 to 0.00917, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 346ms/step - loss: 0.0086 - dice_score: 0.8356 - val_loss: 0.0092 - val_dice_score: 0.8484 - lr: 0.0020\n",
            "Epoch 21/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0083 - dice_score: 0.8407\n",
            "Epoch 21: val_loss did not improve from 0.00917\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0083 - dice_score: 0.8407 - val_loss: 0.0097 - val_dice_score: 0.7936 - lr: 0.0020\n",
            "Epoch 22/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0082 - dice_score: 0.8412\n",
            "Epoch 22: val_loss did not improve from 0.00917\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0082 - dice_score: 0.8412 - val_loss: 0.0101 - val_dice_score: 0.8648 - lr: 0.0020\n",
            "Epoch 23/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0086 - dice_score: 0.8359\n",
            "Epoch 23: val_loss did not improve from 0.00917\n",
            "147/147 [==============================] - 50s 344ms/step - loss: 0.0086 - dice_score: 0.8359 - val_loss: 0.0099 - val_dice_score: 0.8080 - lr: 0.0020\n",
            "Epoch 24/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0081 - dice_score: 0.8427\n",
            "Epoch 24: val_loss improved from 0.00917 to 0.00865, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 345ms/step - loss: 0.0081 - dice_score: 0.8427 - val_loss: 0.0087 - val_dice_score: 0.8255 - lr: 0.0020\n",
            "Epoch 25/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0081 - dice_score: 0.8429\n",
            "Epoch 25: val_loss improved from 0.00865 to 0.00823, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 346ms/step - loss: 0.0081 - dice_score: 0.8429 - val_loss: 0.0082 - val_dice_score: 0.8675 - lr: 0.0020\n",
            "Epoch 26/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0077 - dice_score: 0.8509\n",
            "Epoch 26: val_loss did not improve from 0.00823\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0077 - dice_score: 0.8509 - val_loss: 0.0177 - val_dice_score: 0.6475 - lr: 0.0020\n",
            "Epoch 27/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0076 - dice_score: 0.8530\n",
            "Epoch 27: val_loss did not improve from 0.00823\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0076 - dice_score: 0.8530 - val_loss: 0.0084 - val_dice_score: 0.8249 - lr: 0.0020\n",
            "Epoch 28/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0073 - dice_score: 0.8559\n",
            "Epoch 28: val_loss did not improve from 0.00823\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0073 - dice_score: 0.8559 - val_loss: 0.0121 - val_dice_score: 0.8668 - lr: 0.0020\n",
            "Epoch 29/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0074 - dice_score: 0.8549\n",
            "Epoch 29: val_loss did not improve from 0.00823\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0074 - dice_score: 0.8549 - val_loss: 0.0083 - val_dice_score: 0.8336 - lr: 0.0020\n",
            "Epoch 30/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0073 - dice_score: 0.8569\n",
            "Epoch 30: val_loss improved from 0.00823 to 0.00765, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 345ms/step - loss: 0.0073 - dice_score: 0.8569 - val_loss: 0.0077 - val_dice_score: 0.8484 - lr: 0.0020\n",
            "Epoch 31/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0074 - dice_score: 0.8566\n",
            "Epoch 31: val_loss did not improve from 0.00765\n",
            "147/147 [==============================] - 50s 343ms/step - loss: 0.0074 - dice_score: 0.8566 - val_loss: 0.0096 - val_dice_score: 0.8712 - lr: 0.0020\n",
            "Epoch 32/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0076 - dice_score: 0.8530\n",
            "Epoch 32: val_loss did not improve from 0.00765\n",
            "147/147 [==============================] - 50s 343ms/step - loss: 0.0076 - dice_score: 0.8530 - val_loss: 0.0089 - val_dice_score: 0.8065 - lr: 0.0020\n",
            "Epoch 33/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0071 - dice_score: 0.8612\n",
            "Epoch 33: val_loss did not improve from 0.00765\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0071 - dice_score: 0.8612 - val_loss: 0.0079 - val_dice_score: 0.8295 - lr: 0.0020\n",
            "Epoch 34/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0069 - dice_score: 0.8624\n",
            "Epoch 34: val_loss improved from 0.00765 to 0.00718, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 346ms/step - loss: 0.0069 - dice_score: 0.8624 - val_loss: 0.0072 - val_dice_score: 0.8658 - lr: 0.0020\n",
            "Epoch 35/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0075 - dice_score: 0.8544\n",
            "Epoch 35: val_loss did not improve from 0.00718\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0075 - dice_score: 0.8544 - val_loss: 0.0120 - val_dice_score: 0.7610 - lr: 0.0020\n",
            "Epoch 36/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0070 - dice_score: 0.8623\n",
            "Epoch 36: val_loss did not improve from 0.00718\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0070 - dice_score: 0.8623 - val_loss: 0.0073 - val_dice_score: 0.8545 - lr: 0.0020\n",
            "Epoch 37/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0067 - dice_score: 0.8681\n",
            "Epoch 37: val_loss did not improve from 0.00718\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0067 - dice_score: 0.8681 - val_loss: 0.0079 - val_dice_score: 0.8370 - lr: 0.0020\n",
            "Epoch 38/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0067 - dice_score: 0.8672\n",
            "Epoch 38: val_loss did not improve from 0.00718\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0067 - dice_score: 0.8672 - val_loss: 0.0095 - val_dice_score: 0.8118 - lr: 0.0020\n",
            "Epoch 39/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0066 - dice_score: 0.8709\n",
            "Epoch 39: val_loss did not improve from 0.00718\n",
            "147/147 [==============================] - 50s 343ms/step - loss: 0.0066 - dice_score: 0.8709 - val_loss: 0.0074 - val_dice_score: 0.8571 - lr: 0.0020\n",
            "Epoch 40/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0067 - dice_score: 0.8662\n",
            "Epoch 40: val_loss did not improve from 0.00718\n",
            "147/147 [==============================] - 50s 343ms/step - loss: 0.0067 - dice_score: 0.8662 - val_loss: 0.0083 - val_dice_score: 0.8966 - lr: 0.0020\n",
            "Epoch 41/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0069 - dice_score: 0.8656\n",
            "Epoch 41: val_loss did not improve from 0.00718\n",
            "147/147 [==============================] - 50s 343ms/step - loss: 0.0069 - dice_score: 0.8656 - val_loss: 0.0089 - val_dice_score: 0.7917 - lr: 0.0020\n",
            "Epoch 42/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0064 - dice_score: 0.8729\n",
            "Epoch 42: val_loss did not improve from 0.00718\n",
            "147/147 [==============================] - 50s 343ms/step - loss: 0.0064 - dice_score: 0.8729 - val_loss: 0.0074 - val_dice_score: 0.8548 - lr: 0.0020\n",
            "Epoch 43/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0063 - dice_score: 0.8747\n",
            "Epoch 43: val_loss improved from 0.00718 to 0.00718, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 345ms/step - loss: 0.0063 - dice_score: 0.8747 - val_loss: 0.0072 - val_dice_score: 0.8632 - lr: 0.0020\n",
            "Epoch 44/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0081 - dice_score: 0.8471\n",
            "Epoch 44: val_loss did not improve from 0.00718\n",
            "147/147 [==============================] - 50s 344ms/step - loss: 0.0081 - dice_score: 0.8471 - val_loss: 0.0491 - val_dice_score: 0.7204 - lr: 0.0020\n",
            "Epoch 45/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0064 - dice_score: 0.8715\n",
            "Epoch 45: val_loss did not improve from 0.00718\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0064 - dice_score: 0.8715 - val_loss: 0.0089 - val_dice_score: 0.8313 - lr: 0.0020\n",
            "Epoch 46/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0063 - dice_score: 0.8738\n",
            "Epoch 46: val_loss did not improve from 0.00718\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0063 - dice_score: 0.8738 - val_loss: 0.0209 - val_dice_score: 0.6577 - lr: 0.0020\n",
            "Epoch 47/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0063 - dice_score: 0.8747\n",
            "Epoch 47: val_loss improved from 0.00718 to 0.00700, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 346ms/step - loss: 0.0063 - dice_score: 0.8747 - val_loss: 0.0070 - val_dice_score: 0.8838 - lr: 0.0020\n",
            "Epoch 48/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0060 - dice_score: 0.8801\n",
            "Epoch 48: val_loss improved from 0.00700 to 0.00689, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 346ms/step - loss: 0.0060 - dice_score: 0.8801 - val_loss: 0.0069 - val_dice_score: 0.8701 - lr: 0.0020\n",
            "Epoch 49/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0059 - dice_score: 0.8811\n",
            "Epoch 49: val_loss did not improve from 0.00689\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0059 - dice_score: 0.8811 - val_loss: 0.0072 - val_dice_score: 0.8831 - lr: 0.0020\n",
            "Epoch 50/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0058 - dice_score: 0.8828\n",
            "Epoch 50: val_loss improved from 0.00689 to 0.00681, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 346ms/step - loss: 0.0058 - dice_score: 0.8828 - val_loss: 0.0068 - val_dice_score: 0.8695 - lr: 0.0020\n",
            "Epoch 51/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0058 - dice_score: 0.8844\n",
            "Epoch 51: val_loss improved from 0.00681 to 0.00658, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 346ms/step - loss: 0.0058 - dice_score: 0.8844 - val_loss: 0.0066 - val_dice_score: 0.8719 - lr: 0.0020\n",
            "Epoch 52/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0058 - dice_score: 0.8839\n",
            "Epoch 52: val_loss improved from 0.00658 to 0.00646, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 345ms/step - loss: 0.0058 - dice_score: 0.8839 - val_loss: 0.0065 - val_dice_score: 0.9012 - lr: 0.0020\n",
            "Epoch 53/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0058 - dice_score: 0.8842\n",
            "Epoch 53: val_loss did not improve from 0.00646\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0058 - dice_score: 0.8842 - val_loss: 0.0080 - val_dice_score: 0.8523 - lr: 0.0020\n",
            "Epoch 54/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0057 - dice_score: 0.8853\n",
            "Epoch 54: val_loss did not improve from 0.00646\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0057 - dice_score: 0.8853 - val_loss: 0.0074 - val_dice_score: 0.8979 - lr: 0.0020\n",
            "Epoch 55/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0057 - dice_score: 0.8857\n",
            "Epoch 55: val_loss did not improve from 0.00646\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0057 - dice_score: 0.8857 - val_loss: 0.0075 - val_dice_score: 0.8297 - lr: 0.0020\n",
            "Epoch 56/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0055 - dice_score: 0.8885\n",
            "Epoch 56: val_loss improved from 0.00646 to 0.00626, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 346ms/step - loss: 0.0055 - dice_score: 0.8885 - val_loss: 0.0063 - val_dice_score: 0.8978 - lr: 0.0020\n",
            "Epoch 57/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0056 - dice_score: 0.8862\n",
            "Epoch 57: val_loss did not improve from 0.00626\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0056 - dice_score: 0.8862 - val_loss: 0.0068 - val_dice_score: 0.8802 - lr: 0.0020\n",
            "Epoch 58/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0055 - dice_score: 0.8892\n",
            "Epoch 58: val_loss did not improve from 0.00626\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0055 - dice_score: 0.8892 - val_loss: 0.0065 - val_dice_score: 0.8697 - lr: 0.0020\n",
            "Epoch 59/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0055 - dice_score: 0.8865\n",
            "Epoch 59: val_loss did not improve from 0.00626\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0055 - dice_score: 0.8865 - val_loss: 0.0087 - val_dice_score: 0.8304 - lr: 0.0020\n",
            "Epoch 60/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0054 - dice_score: 0.8907\n",
            "Epoch 60: val_loss did not improve from 0.00626\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0054 - dice_score: 0.8907 - val_loss: 0.0065 - val_dice_score: 0.8757 - lr: 0.0020\n",
            "Epoch 61/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0053 - dice_score: 0.8923\n",
            "Epoch 61: val_loss did not improve from 0.00626\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0053 - dice_score: 0.8923 - val_loss: 0.0069 - val_dice_score: 0.8635 - lr: 0.0020\n",
            "Epoch 62/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0053 - dice_score: 0.8907\n",
            "Epoch 62: val_loss did not improve from 0.00626\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0053 - dice_score: 0.8907 - val_loss: 0.0063 - val_dice_score: 0.8638 - lr: 0.0020\n",
            "Epoch 63/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0053 - dice_score: 0.8920\n",
            "Epoch 63: val_loss did not improve from 0.00626\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0053 - dice_score: 0.8920 - val_loss: 0.0069 - val_dice_score: 0.8743 - lr: 0.0020\n",
            "Epoch 64/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0052 - dice_score: 0.8930\n",
            "Epoch 64: val_loss improved from 0.00626 to 0.00605, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 346ms/step - loss: 0.0052 - dice_score: 0.8930 - val_loss: 0.0060 - val_dice_score: 0.8987 - lr: 0.0020\n",
            "Epoch 65/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0051 - dice_score: 0.8951\n",
            "Epoch 65: val_loss did not improve from 0.00605\n",
            "147/147 [==============================] - 51s 345ms/step - loss: 0.0051 - dice_score: 0.8951 - val_loss: 0.0076 - val_dice_score: 0.9175 - lr: 0.0020\n",
            "Epoch 66/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0052 - dice_score: 0.8925\n",
            "Epoch 66: val_loss did not improve from 0.00605\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0052 - dice_score: 0.8925 - val_loss: 0.0062 - val_dice_score: 0.8983 - lr: 0.0020\n",
            "Epoch 67/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0051 - dice_score: 0.8941\n",
            "Epoch 67: val_loss improved from 0.00605 to 0.00604, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 346ms/step - loss: 0.0051 - dice_score: 0.8941 - val_loss: 0.0060 - val_dice_score: 0.8925 - lr: 0.0020\n",
            "Epoch 68/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0050 - dice_score: 0.8957\n",
            "Epoch 68: val_loss did not improve from 0.00604\n",
            "147/147 [==============================] - 50s 343ms/step - loss: 0.0050 - dice_score: 0.8957 - val_loss: 0.0064 - val_dice_score: 0.8871 - lr: 0.0020\n",
            "Epoch 69/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0050 - dice_score: 0.8985\n",
            "Epoch 69: val_loss improved from 0.00604 to 0.00599, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 345ms/step - loss: 0.0050 - dice_score: 0.8985 - val_loss: 0.0060 - val_dice_score: 0.8989 - lr: 0.0020\n",
            "Epoch 70/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0049 - dice_score: 0.8971\n",
            "Epoch 70: val_loss did not improve from 0.00599\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0049 - dice_score: 0.8971 - val_loss: 0.0064 - val_dice_score: 0.9045 - lr: 0.0020\n",
            "Epoch 71/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0051 - dice_score: 0.8951\n",
            "Epoch 71: val_loss did not improve from 0.00599\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0051 - dice_score: 0.8951 - val_loss: 0.0062 - val_dice_score: 0.8662 - lr: 0.0020\n",
            "Epoch 72/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0051 - dice_score: 0.8958\n",
            "Epoch 72: val_loss did not improve from 0.00599\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0051 - dice_score: 0.8958 - val_loss: 0.0069 - val_dice_score: 0.8521 - lr: 0.0020\n",
            "Epoch 73/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0049 - dice_score: 0.8987\n",
            "Epoch 73: val_loss improved from 0.00599 to 0.00581, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 346ms/step - loss: 0.0049 - dice_score: 0.8987 - val_loss: 0.0058 - val_dice_score: 0.8931 - lr: 0.0020\n",
            "Epoch 74/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0048 - dice_score: 0.9008\n",
            "Epoch 74: val_loss improved from 0.00581 to 0.00567, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 345ms/step - loss: 0.0048 - dice_score: 0.9008 - val_loss: 0.0057 - val_dice_score: 0.8810 - lr: 0.0020\n",
            "Epoch 75/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0047 - dice_score: 0.9022\n",
            "Epoch 75: val_loss did not improve from 0.00567\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0047 - dice_score: 0.9022 - val_loss: 0.0062 - val_dice_score: 0.8842 - lr: 0.0020\n",
            "Epoch 76/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0047 - dice_score: 0.9028\n",
            "Epoch 76: val_loss improved from 0.00567 to 0.00560, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 346ms/step - loss: 0.0047 - dice_score: 0.9028 - val_loss: 0.0056 - val_dice_score: 0.9005 - lr: 0.0020\n",
            "Epoch 77/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0047 - dice_score: 0.9021\n",
            "Epoch 77: val_loss did not improve from 0.00560\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0047 - dice_score: 0.9021 - val_loss: 0.0057 - val_dice_score: 0.8931 - lr: 0.0020\n",
            "Epoch 78/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0047 - dice_score: 0.9034\n",
            "Epoch 78: val_loss did not improve from 0.00560\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0047 - dice_score: 0.9034 - val_loss: 0.0058 - val_dice_score: 0.8877 - lr: 0.0020\n",
            "Epoch 79/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0047 - dice_score: 0.9021\n",
            "Epoch 79: val_loss did not improve from 0.00560\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0047 - dice_score: 0.9021 - val_loss: 0.0062 - val_dice_score: 0.9068 - lr: 0.0020\n",
            "Epoch 80/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0046 - dice_score: 0.9034\n",
            "Epoch 80: val_loss did not improve from 0.00560\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0046 - dice_score: 0.9034 - val_loss: 0.0077 - val_dice_score: 0.8578 - lr: 0.0020\n",
            "Epoch 81/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0045 - dice_score: 0.9065\n",
            "Epoch 81: val_loss did not improve from 0.00560\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0045 - dice_score: 0.9065 - val_loss: 0.0062 - val_dice_score: 0.9083 - lr: 0.0020\n",
            "Epoch 82/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0044 - dice_score: 0.9074\n",
            "Epoch 82: val_loss did not improve from 0.00560\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0044 - dice_score: 0.9074 - val_loss: 0.0059 - val_dice_score: 0.9158 - lr: 0.0020\n",
            "Epoch 83/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0046 - dice_score: 0.9041\n",
            "Epoch 83: val_loss did not improve from 0.00560\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0046 - dice_score: 0.9041 - val_loss: 0.0062 - val_dice_score: 0.8728 - lr: 0.0020\n",
            "Epoch 84/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0046 - dice_score: 0.9036\n",
            "Epoch 84: val_loss did not improve from 0.00560\n",
            "147/147 [==============================] - 50s 344ms/step - loss: 0.0046 - dice_score: 0.9036 - val_loss: 0.0063 - val_dice_score: 0.8801 - lr: 0.0020\n",
            "Epoch 85/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0046 - dice_score: 0.9055\n",
            "Epoch 85: val_loss did not improve from 0.00560\n",
            "147/147 [==============================] - 50s 343ms/step - loss: 0.0046 - dice_score: 0.9055 - val_loss: 0.0098 - val_dice_score: 0.8186 - lr: 0.0020\n",
            "Epoch 86/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0046 - dice_score: 0.9048\n",
            "Epoch 86: val_loss did not improve from 0.00560\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0046 - dice_score: 0.9048 - val_loss: 0.0057 - val_dice_score: 0.9043 - lr: 0.0020\n",
            "Epoch 87/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0044 - dice_score: 0.9080\n",
            "Epoch 87: val_loss improved from 0.00560 to 0.00557, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 346ms/step - loss: 0.0044 - dice_score: 0.9080 - val_loss: 0.0056 - val_dice_score: 0.9106 - lr: 0.0020\n",
            "Epoch 88/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0046 - dice_score: 0.9041\n",
            "Epoch 88: val_loss did not improve from 0.00557\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0046 - dice_score: 0.9041 - val_loss: 0.0061 - val_dice_score: 0.9243 - lr: 0.0020\n",
            "Epoch 89/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0045 - dice_score: 0.9063\n",
            "Epoch 89: val_loss did not improve from 0.00557\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0045 - dice_score: 0.9063 - val_loss: 0.0070 - val_dice_score: 0.8607 - lr: 0.0020\n",
            "Epoch 90/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0044 - dice_score: 0.9093\n",
            "Epoch 90: val_loss did not improve from 0.00557\n",
            "147/147 [==============================] - 50s 343ms/step - loss: 0.0044 - dice_score: 0.9093 - val_loss: 0.0062 - val_dice_score: 0.9012 - lr: 0.0020\n",
            "Epoch 91/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0043 - dice_score: 0.9107\n",
            "Epoch 91: val_loss improved from 0.00557 to 0.00553, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 345ms/step - loss: 0.0043 - dice_score: 0.9107 - val_loss: 0.0055 - val_dice_score: 0.9151 - lr: 0.0020\n",
            "Epoch 92/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0042 - dice_score: 0.9123\n",
            "Epoch 92: val_loss did not improve from 0.00553\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0042 - dice_score: 0.9123 - val_loss: 0.0061 - val_dice_score: 0.9254 - lr: 0.0020\n",
            "Epoch 93/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0043 - dice_score: 0.9106\n",
            "Epoch 93: val_loss improved from 0.00553 to 0.00551, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 346ms/step - loss: 0.0043 - dice_score: 0.9106 - val_loss: 0.0055 - val_dice_score: 0.8909 - lr: 0.0020\n",
            "Epoch 94/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0044 - dice_score: 0.9098\n",
            "Epoch 94: val_loss did not improve from 0.00551\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0044 - dice_score: 0.9098 - val_loss: 0.0058 - val_dice_score: 0.8943 - lr: 0.0020\n",
            "Epoch 95/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0042 - dice_score: 0.9126\n",
            "Epoch 95: val_loss improved from 0.00551 to 0.00535, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 346ms/step - loss: 0.0042 - dice_score: 0.9126 - val_loss: 0.0053 - val_dice_score: 0.8973 - lr: 0.0020\n",
            "Epoch 96/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0042 - dice_score: 0.9113\n",
            "Epoch 96: val_loss improved from 0.00535 to 0.00534, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 346ms/step - loss: 0.0042 - dice_score: 0.9113 - val_loss: 0.0053 - val_dice_score: 0.9071 - lr: 0.0020\n",
            "Epoch 97/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0041 - dice_score: 0.9135\n",
            "Epoch 97: val_loss did not improve from 0.00534\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0041 - dice_score: 0.9135 - val_loss: 0.0055 - val_dice_score: 0.9172 - lr: 0.0020\n",
            "Epoch 98/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0042 - dice_score: 0.9132\n",
            "Epoch 98: val_loss did not improve from 0.00534\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0042 - dice_score: 0.9132 - val_loss: 0.0054 - val_dice_score: 0.9044 - lr: 0.0020\n",
            "Epoch 99/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0042 - dice_score: 0.9134\n",
            "Epoch 99: val_loss improved from 0.00534 to 0.00518, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 346ms/step - loss: 0.0042 - dice_score: 0.9134 - val_loss: 0.0052 - val_dice_score: 0.9056 - lr: 0.0020\n",
            "Epoch 100/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0041 - dice_score: 0.9135\n",
            "Epoch 100: val_loss did not improve from 0.00518\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0041 - dice_score: 0.9135 - val_loss: 0.0057 - val_dice_score: 0.8878 - lr: 0.0020\n",
            "Epoch 101/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0041 - dice_score: 0.9145\n",
            "Epoch 101: val_loss did not improve from 0.00518\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0041 - dice_score: 0.9145 - val_loss: 0.0052 - val_dice_score: 0.9047 - lr: 0.0020\n",
            "Epoch 102/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0041 - dice_score: 0.9143\n",
            "Epoch 102: val_loss did not improve from 0.00518\n",
            "147/147 [==============================] - 50s 343ms/step - loss: 0.0041 - dice_score: 0.9143 - val_loss: 0.0060 - val_dice_score: 0.8805 - lr: 0.0020\n",
            "Epoch 103/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0041 - dice_score: 0.9151\n",
            "Epoch 103: val_loss did not improve from 0.00518\n",
            "147/147 [==============================] - 50s 343ms/step - loss: 0.0041 - dice_score: 0.9151 - val_loss: 0.0240 - val_dice_score: 0.6720 - lr: 0.0020\n",
            "Epoch 104/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0042 - dice_score: 0.9120\n",
            "Epoch 104: val_loss did not improve from 0.00518\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0042 - dice_score: 0.9120 - val_loss: 0.0057 - val_dice_score: 0.8946 - lr: 0.0020\n",
            "Epoch 105/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0040 - dice_score: 0.9153\n",
            "Epoch 105: val_loss did not improve from 0.00518\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0040 - dice_score: 0.9153 - val_loss: 0.0055 - val_dice_score: 0.9225 - lr: 0.0020\n",
            "Epoch 106/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0040 - dice_score: 0.9160\n",
            "Epoch 106: val_loss did not improve from 0.00518\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0040 - dice_score: 0.9160 - val_loss: 0.0052 - val_dice_score: 0.9142 - lr: 0.0020\n",
            "Epoch 107/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0040 - dice_score: 0.9166\n",
            "Epoch 107: val_loss improved from 0.00518 to 0.00510, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 346ms/step - loss: 0.0040 - dice_score: 0.9166 - val_loss: 0.0051 - val_dice_score: 0.9017 - lr: 0.0020\n",
            "Epoch 108/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0039 - dice_score: 0.9181\n",
            "Epoch 108: val_loss did not improve from 0.00510\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0039 - dice_score: 0.9181 - val_loss: 0.0053 - val_dice_score: 0.9007 - lr: 0.0020\n",
            "Epoch 109/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0041 - dice_score: 0.9170\n",
            "Epoch 109: val_loss did not improve from 0.00510\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0041 - dice_score: 0.9170 - val_loss: 0.3033 - val_dice_score: 0.2479 - lr: 0.0020\n",
            "Epoch 110/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0064 - dice_score: 0.8770\n",
            "Epoch 110: val_loss did not improve from 0.00510\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0064 - dice_score: 0.8770 - val_loss: 0.0061 - val_dice_score: 0.8888 - lr: 0.0020\n",
            "Epoch 111/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0042 - dice_score: 0.9141\n",
            "Epoch 111: val_loss did not improve from 0.00510\n",
            "147/147 [==============================] - 50s 343ms/step - loss: 0.0042 - dice_score: 0.9141 - val_loss: 0.0053 - val_dice_score: 0.9007 - lr: 0.0020\n",
            "Epoch 112/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0040 - dice_score: 0.9160\n",
            "Epoch 112: val_loss did not improve from 0.00510\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0040 - dice_score: 0.9160 - val_loss: 0.0055 - val_dice_score: 0.9015 - lr: 0.0020\n",
            "Epoch 113/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0039 - dice_score: 0.9185\n",
            "Epoch 113: val_loss improved from 0.00510 to 0.00509, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 346ms/step - loss: 0.0039 - dice_score: 0.9185 - val_loss: 0.0051 - val_dice_score: 0.9113 - lr: 0.0020\n",
            "Epoch 114/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0039 - dice_score: 0.9169\n",
            "Epoch 114: val_loss did not improve from 0.00509\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0039 - dice_score: 0.9169 - val_loss: 0.0053 - val_dice_score: 0.9063 - lr: 0.0020\n",
            "Epoch 115/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0038 - dice_score: 0.9195\n",
            "Epoch 115: val_loss did not improve from 0.00509\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0038 - dice_score: 0.9195 - val_loss: 0.0053 - val_dice_score: 0.9108 - lr: 0.0020\n",
            "Epoch 116/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0038 - dice_score: 0.9196\n",
            "Epoch 116: val_loss did not improve from 0.00509\n",
            "147/147 [==============================] - 50s 343ms/step - loss: 0.0038 - dice_score: 0.9196 - val_loss: 0.0057 - val_dice_score: 0.8923 - lr: 0.0020\n",
            "Epoch 117/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0038 - dice_score: 0.9192\n",
            "Epoch 117: val_loss did not improve from 0.00509\n",
            "147/147 [==============================] - 50s 343ms/step - loss: 0.0038 - dice_score: 0.9192 - val_loss: 0.0056 - val_dice_score: 0.9133 - lr: 0.0020\n",
            "Epoch 118/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0038 - dice_score: 0.9209\n",
            "Epoch 118: val_loss did not improve from 0.00509\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0038 - dice_score: 0.9209 - val_loss: 0.0051 - val_dice_score: 0.9146 - lr: 0.0020\n",
            "Epoch 119/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0037 - dice_score: 0.9212\n",
            "Epoch 119: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
            "\n",
            "Epoch 119: val_loss did not improve from 0.00509\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0037 - dice_score: 0.9212 - val_loss: 0.0054 - val_dice_score: 0.9160 - lr: 0.0020\n",
            "Epoch 120/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0036 - dice_score: 0.9231\n",
            "Epoch 120: val_loss did not improve from 0.00509\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0036 - dice_score: 0.9231 - val_loss: 0.0053 - val_dice_score: 0.9055 - lr: 0.0010\n",
            "Epoch 121/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0035 - dice_score: 0.9248\n",
            "Epoch 121: val_loss improved from 0.00509 to 0.00503, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 346ms/step - loss: 0.0035 - dice_score: 0.9248 - val_loss: 0.0050 - val_dice_score: 0.9218 - lr: 0.0010\n",
            "Epoch 122/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0035 - dice_score: 0.9250\n",
            "Epoch 122: val_loss did not improve from 0.00503\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0035 - dice_score: 0.9250 - val_loss: 0.0051 - val_dice_score: 0.9054 - lr: 0.0010\n",
            "Epoch 123/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0035 - dice_score: 0.9249\n",
            "Epoch 123: val_loss did not improve from 0.00503\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0035 - dice_score: 0.9249 - val_loss: 0.0050 - val_dice_score: 0.9214 - lr: 0.0010\n",
            "Epoch 124/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0035 - dice_score: 0.9255\n",
            "Epoch 124: val_loss improved from 0.00503 to 0.00494, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 346ms/step - loss: 0.0035 - dice_score: 0.9255 - val_loss: 0.0049 - val_dice_score: 0.9208 - lr: 0.0010\n",
            "Epoch 125/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0035 - dice_score: 0.9261\n",
            "Epoch 125: val_loss did not improve from 0.00494\n",
            "147/147 [==============================] - 50s 343ms/step - loss: 0.0035 - dice_score: 0.9261 - val_loss: 0.0052 - val_dice_score: 0.9237 - lr: 0.0010\n",
            "Epoch 126/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0035 - dice_score: 0.9256\n",
            "Epoch 126: val_loss did not improve from 0.00494\n",
            "147/147 [==============================] - 50s 344ms/step - loss: 0.0035 - dice_score: 0.9256 - val_loss: 0.0051 - val_dice_score: 0.9234 - lr: 0.0010\n",
            "Epoch 127/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0035 - dice_score: 0.9262\n",
            "Epoch 127: val_loss did not improve from 0.00494\n",
            "147/147 [==============================] - 50s 344ms/step - loss: 0.0035 - dice_score: 0.9262 - val_loss: 0.0050 - val_dice_score: 0.9144 - lr: 0.0010\n",
            "Epoch 128/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0035 - dice_score: 0.9254\n",
            "Epoch 128: val_loss did not improve from 0.00494\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0035 - dice_score: 0.9254 - val_loss: 0.0050 - val_dice_score: 0.9190 - lr: 0.0010\n",
            "Epoch 129/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0034 - dice_score: 0.9270\n",
            "Epoch 129: val_loss did not improve from 0.00494\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0034 - dice_score: 0.9270 - val_loss: 0.0051 - val_dice_score: 0.9195 - lr: 0.0010\n",
            "Epoch 130/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0035 - dice_score: 0.9257\n",
            "Epoch 130: val_loss did not improve from 0.00494\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0035 - dice_score: 0.9257 - val_loss: 0.0050 - val_dice_score: 0.9164 - lr: 0.0010\n",
            "Epoch 131/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0035 - dice_score: 0.9262\n",
            "Epoch 131: val_loss did not improve from 0.00494\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0035 - dice_score: 0.9262 - val_loss: 0.0050 - val_dice_score: 0.9174 - lr: 0.0010\n",
            "Epoch 132/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0035 - dice_score: 0.9260\n",
            "Epoch 132: val_loss did not improve from 0.00494\n",
            "147/147 [==============================] - 50s 344ms/step - loss: 0.0035 - dice_score: 0.9260 - val_loss: 0.0050 - val_dice_score: 0.9193 - lr: 0.0010\n",
            "Epoch 133/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0034 - dice_score: 0.9275\n",
            "Epoch 133: val_loss did not improve from 0.00494\n",
            "147/147 [==============================] - 50s 343ms/step - loss: 0.0034 - dice_score: 0.9275 - val_loss: 0.0050 - val_dice_score: 0.9176 - lr: 0.0010\n",
            "Epoch 134/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0034 - dice_score: 0.9272\n",
            "Epoch 134: val_loss improved from 0.00494 to 0.00491, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 345ms/step - loss: 0.0034 - dice_score: 0.9272 - val_loss: 0.0049 - val_dice_score: 0.9161 - lr: 0.0010\n",
            "Epoch 135/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0034 - dice_score: 0.9271\n",
            "Epoch 135: val_loss did not improve from 0.00491\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0034 - dice_score: 0.9271 - val_loss: 0.0049 - val_dice_score: 0.9182 - lr: 0.0010\n",
            "Epoch 136/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0034 - dice_score: 0.9273\n",
            "Epoch 136: val_loss did not improve from 0.00491\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0034 - dice_score: 0.9273 - val_loss: 0.0054 - val_dice_score: 0.9278 - lr: 0.0010\n",
            "Epoch 137/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0034 - dice_score: 0.9267\n",
            "Epoch 137: val_loss did not improve from 0.00491\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0034 - dice_score: 0.9267 - val_loss: 0.0050 - val_dice_score: 0.9147 - lr: 0.0010\n",
            "Epoch 138/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0034 - dice_score: 0.9280\n",
            "Epoch 138: val_loss did not improve from 0.00491\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0034 - dice_score: 0.9280 - val_loss: 0.0049 - val_dice_score: 0.9188 - lr: 0.0010\n",
            "Epoch 139/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0034 - dice_score: 0.9270\n",
            "Epoch 139: val_loss did not improve from 0.00491\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0034 - dice_score: 0.9270 - val_loss: 0.0052 - val_dice_score: 0.9274 - lr: 0.0010\n",
            "Epoch 140/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0034 - dice_score: 0.9278\n",
            "Epoch 140: val_loss did not improve from 0.00491\n",
            "147/147 [==============================] - 50s 343ms/step - loss: 0.0034 - dice_score: 0.9278 - val_loss: 0.0051 - val_dice_score: 0.9264 - lr: 0.0010\n",
            "Epoch 141/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0033 - dice_score: 0.9285\n",
            "Epoch 141: val_loss did not improve from 0.00491\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0033 - dice_score: 0.9285 - val_loss: 0.0052 - val_dice_score: 0.9069 - lr: 0.0010\n",
            "Epoch 142/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0034 - dice_score: 0.9275\n",
            "Epoch 142: val_loss did not improve from 0.00491\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0034 - dice_score: 0.9275 - val_loss: 0.0049 - val_dice_score: 0.9119 - lr: 0.0010\n",
            "Epoch 143/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0033 - dice_score: 0.9288\n",
            "Epoch 143: val_loss did not improve from 0.00491\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0033 - dice_score: 0.9288 - val_loss: 0.0052 - val_dice_score: 0.9261 - lr: 0.0010\n",
            "Epoch 144/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0033 - dice_score: 0.9279\n",
            "Epoch 144: val_loss improved from 0.00491 to 0.00488, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 346ms/step - loss: 0.0033 - dice_score: 0.9279 - val_loss: 0.0049 - val_dice_score: 0.9230 - lr: 0.0010\n",
            "Epoch 145/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0033 - dice_score: 0.9299\n",
            "Epoch 145: val_loss improved from 0.00488 to 0.00484, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 346ms/step - loss: 0.0033 - dice_score: 0.9299 - val_loss: 0.0048 - val_dice_score: 0.9227 - lr: 0.0010\n",
            "Epoch 146/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0033 - dice_score: 0.9290\n",
            "Epoch 146: val_loss did not improve from 0.00484\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0033 - dice_score: 0.9290 - val_loss: 0.0049 - val_dice_score: 0.9204 - lr: 0.0010\n",
            "Epoch 147/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0033 - dice_score: 0.9299\n",
            "Epoch 147: val_loss did not improve from 0.00484\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0033 - dice_score: 0.9299 - val_loss: 0.0049 - val_dice_score: 0.9179 - lr: 0.0010\n",
            "Epoch 148/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0033 - dice_score: 0.9291\n",
            "Epoch 148: val_loss did not improve from 0.00484\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0033 - dice_score: 0.9291 - val_loss: 0.0049 - val_dice_score: 0.9131 - lr: 0.0010\n",
            "Epoch 149/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0033 - dice_score: 0.9301\n",
            "Epoch 149: val_loss did not improve from 0.00484\n",
            "147/147 [==============================] - 51s 344ms/step - loss: 0.0033 - dice_score: 0.9301 - val_loss: 0.0052 - val_dice_score: 0.9297 - lr: 0.0010\n",
            "Epoch 150/150\n",
            "147/147 [==============================] - ETA: 0s - loss: 0.0033 - dice_score: 0.9302\n",
            "Epoch 150: val_loss improved from 0.00484 to 0.00471, saving model to ./weights/best_model.h5\n",
            "147/147 [==============================] - 51s 346ms/step - loss: 0.0033 - dice_score: 0.9302 - val_loss: 0.0047 - val_dice_score: 0.9144 - lr: 0.0010\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "class U_Net():\n",
        "    def __init__(self):\n",
        "        # init the parameters and inputs\n",
        "        self.height = 240\n",
        "        self.width = 240\n",
        "        self.channels = 1\n",
        "        self.shape = (self.height, self.width, self.channels)\n",
        "\n",
        "        # optimizer\n",
        "        optimizer = Adam(0.002, 0.5)\n",
        "\n",
        "        # u_net\n",
        "        self.unet = self.build_unet()  # create a model\n",
        "        self.unet.compile(loss='binary_crossentropy',\n",
        "                          optimizer=optimizer,\n",
        "                          metrics=[self.dice_score])\n",
        "        self.unet.summary()\n",
        "\n",
        "    def build_unet(self, n_filters=16, dropout=0.5, batchnorm=True, padding='same'):\n",
        "\n",
        "        # defin a convolutional clock\n",
        "        def conv2d_block(input_tensor, n_filters=16, kernel_size=3, batchnorm=True, padding='same'):\n",
        "            # the first layer\n",
        "            x = Conv2D(n_filters, kernel_size, padding=padding)(\n",
        "                input_tensor)\n",
        "            if batchnorm:\n",
        "                x = BatchNormalization()(x)\n",
        "            x = Activation('relu')(x)\n",
        "\n",
        "            # the second layer\n",
        "            x = Conv2D(n_filters, kernel_size, padding=padding)(x)\n",
        "            if batchnorm:\n",
        "                x = BatchNormalization()(x)\n",
        "            X = Activation('relu')(x)\n",
        "            return X\n",
        "        # build an input\n",
        "        img = Input(shape=self.shape)\n",
        "\n",
        "        # contracting path\n",
        "        c1 = conv2d_block(img, n_filters=n_filters * 1, kernel_size=3, batchnorm=batchnorm, padding=padding)\n",
        "        p1 = MaxPooling2D((2, 2))(c1)\n",
        "        p1 = Dropout(dropout * 0.5)(p1)\n",
        "\n",
        "        c2 = conv2d_block(p1, n_filters=n_filters * 2, kernel_size=3, batchnorm=batchnorm, padding=padding)\n",
        "        p2 = MaxPooling2D((2, 2))(c2)\n",
        "        p2 = Dropout(dropout)(p2)\n",
        "\n",
        "        c3 = conv2d_block(p2, n_filters=n_filters * 4, kernel_size=3, batchnorm=batchnorm, padding=padding)\n",
        "        p3 = MaxPooling2D((2, 2))(c3)\n",
        "        p3 = Dropout(dropout)(p3)\n",
        "\n",
        "        c4 = conv2d_block(p3, n_filters=n_filters * 8, kernel_size=3, batchnorm=batchnorm, padding=padding)\n",
        "        p4 = MaxPooling2D((2, 2))(c4)\n",
        "        p4 = Dropout(dropout)(p4)\n",
        "\n",
        "        c5 = conv2d_block(p4, n_filters=n_filters * 16, kernel_size=3, batchnorm=batchnorm, padding=padding)\n",
        "\n",
        "        # extending path\n",
        "        u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides=(2, 2), padding='same')(c5)\n",
        "        u6 = concatenate([u6, c4])\n",
        "        u6 = Dropout(dropout)(u6)\n",
        "        c6 = conv2d_block(u6, n_filters=n_filters * 8, kernel_size=3, batchnorm=batchnorm, padding=padding)\n",
        "\n",
        "        u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides=(2, 2), padding='same')(c6)\n",
        "        u7 = concatenate([u7, c3])\n",
        "        u7 = Dropout(dropout)(u7)\n",
        "        c7 = conv2d_block(u7, n_filters=n_filters * 4, kernel_size=3, batchnorm=batchnorm, padding=padding)\n",
        "\n",
        "        u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides=(2, 2), padding='same')(c7)\n",
        "        u8 = concatenate([u8, c2])\n",
        "        u8 = Dropout(dropout)(u8)\n",
        "        c8 = conv2d_block(u8, n_filters=n_filters * 2, kernel_size=3, batchnorm=batchnorm, padding=padding)\n",
        "\n",
        "        u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides=(2, 2), padding='same')(c8)\n",
        "        u9 = concatenate([u9, c1])\n",
        "        u9 = Dropout(dropout)(u9)\n",
        "        c9 = conv2d_block(u9, n_filters=n_filters * 1, kernel_size=3, batchnorm=batchnorm, padding=padding)\n",
        "\n",
        "        output = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "\n",
        "        return Model(img, output)\n",
        "\n",
        "    def dice_score(self, y_true, y_pred):\n",
        "        predict = tf.reduce_sum(2 * y_true * tf.cast(tf.greater(y_pred, 0.1), tf.float32)) + 1e-8\n",
        "        validation = tf.reduce_sum(y_true + tf.cast(tf.greater(y_pred, 0.1), tf.float32)) + 1e-8\n",
        "        return predict / validation\n",
        "\n",
        "    def iou_numpy(self, y_true, y_pred):\n",
        "        intersection = np.sum(np.multiply(y_true.astype('bool'),y_pred == 1))\n",
        "        union = np.sum((y_true.astype('bool')+y_pred.astype('bool'))>0)\n",
        "        return intersection/union\n",
        "    \n",
        "\n",
        "    def load_data(self):\n",
        "        x_train = []\n",
        "        x_label = []\n",
        "        img_path = '/content/drive/MyDrive/tech_project/Dataset/'\n",
        "\n",
        "        for CLASS in os.listdir(img_path):\n",
        "          if not CLASS.startswith('.'):\n",
        "            all_files = os.listdir(img_path + CLASS) # run so long ...\n",
        "            files = [item for item in all_files if \"img\" in item]\n",
        "            random.shuffle(files)\n",
        "            img_num = len(files)\n",
        "            for (n, file_name) in enumerate(files):\n",
        "              img = np.load(os.path.join(img_path,CLASS,file_name))[:,:,0]\n",
        "              x_train.append(img)\n",
        "              seg = np.load(os.path.join(img_path,CLASS,file_name.split('_')[0]+'_seg.npy'))\n",
        "              x_label.append(seg)\n",
        "\n",
        "        x_train = np.expand_dims(np.array(x_train), axis=3)  # extend a dimension (batch0)\n",
        "        x_label = np.expand_dims(np.array(x_label), axis=3)  # the input of net is (num, 240, 240, 1)\n",
        "        np.random.seed(6)  # set a random seed\n",
        "        np.random.shuffle(x_train)  # shuffle the first dimension\n",
        "        np.random.seed(6)\n",
        "        np.random.shuffle(x_label)\n",
        "        # split the data set in 8 to 1\n",
        "        return x_train[:5222, :, :], x_label[:5222, :, :], x_train[5222:, :, :], x_label[5222:, :, :]\n",
        "\n",
        "    def train(self, epochs=150, batch_size=32):\n",
        "        os.makedirs('./weights', exist_ok=True)\n",
        "        # get the dataset\n",
        "        x_train, x_label, y_train, y_label = self.load_data()\n",
        "\n",
        "        # load the model\n",
        "        # self.unet.load_weights(r\"./best_model.h5\")\n",
        "\n",
        "        # use earlystopping to set a checkpoint\n",
        "        callbacks = [EarlyStopping(patience=100, verbose=1),\n",
        "                     ReduceLROnPlateau(factor=0.5, patience=20, min_lr=0.00005, verbose=1),\n",
        "                     ModelCheckpoint('./weights/best_model.h5', verbose=1, save_best_only=True)]\n",
        "\n",
        "        # start the train\n",
        "        results = self.unet.fit(x_train, x_label, batch_size=batch_size, epochs=epochs, verbose=1,\n",
        "                                callbacks=callbacks, validation_split=0.1, shuffle=True)\n",
        "\n",
        "        # plt the curve of training\n",
        "        loss = results.history['loss']\n",
        "        val_loss = results.history['val_loss']\n",
        "        metric = results.history['dice_score']\n",
        "        val_metric = results.history['val_dice_score']\n",
        "        fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
        "        x = np.linspace(0, len(loss), len(loss))  # Create abscissa\n",
        "        plt.subplot(121), plt.plot(x, loss, x, val_loss)\n",
        "        plt.title(\"The Loss curve\"), plt.legend(['loss', 'val_loss'])\n",
        "        plt.xlabel(\"Epochs\"), plt.ylabel(\"loss\")\n",
        "        plt.subplot(122), plt.plot(x, metric, x, val_metric)\n",
        "        plt.title(\"The dice curve\"), plt.legend(['dice', 'val_dice'])\n",
        "        plt.xlabel(\"Epochs\"), plt.ylabel(\"Dice\")\n",
        "        plt.show()\n",
        "        os.makedirs('./evaluation/test_result', exist_ok=True)\n",
        "        fig.savefig('./evaluation/curve.png', bbox_inches='tight', pad_inches=0.1)  # save the pictures of curve\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "    def test_random(self, batch_size=1):\n",
        "        self.unet.load_weights(r\"weights/best_model.h5\")\n",
        "        # get the data\n",
        "        x_train, x_label, y_train, y_label = self.load_data()\n",
        "        test_num = y_train.shape[0]\n",
        "        for epoch in range(5):\n",
        "            rand_index = []\n",
        "            while len(rand_index) < 3:\n",
        "                np.random.seed()\n",
        "                temp = np.random.randint(0, test_num, 1)\n",
        "                if np.sum(x_label[temp]) > 0:\n",
        "                    rand_index.append(temp)\n",
        "            rand_index = np.array(rand_index).squeeze()\n",
        "            fig, ax = plt.subplots(3, 3, figsize=(18, 18))\n",
        "            for i, index in enumerate(rand_index):\n",
        "                mask = self.unet.predict(x_train[index:index + 1]) > 0.5\n",
        "                ax[i][0].imshow(x_train[index].squeeze(), cmap='gray')\n",
        "                ax[i][0].set_title('network input', fontsize=20)\n",
        "                # caclulate the dice and shown\n",
        "                fz = 2 * np.sum(mask.squeeze() * x_label[index].squeeze())\n",
        "                fm = np.sum(mask.squeeze()) + np.sum(x_label[index].squeeze())\n",
        "                dice = fz / fm\n",
        "                ax[i][1].imshow(mask.squeeze())\n",
        "                ax[i][1].set_title('network output(%.4f)' % dice, fontsize=20)  # write a title\n",
        "                ax[i][2].imshow(x_label[index].squeeze())\n",
        "                ax[i][2].set_title('mask label', fontsize=20)\n",
        "            fig.savefig('./evaluationow%d_%d_%d.png' % (rand_index[0], rand_index[1], rand_index[2]),\n",
        "                        bbox_inches='tight', pad_inches=0.1)  # save pictures\n",
        "            print('finished epoch: %d' % epoch)\n",
        "            plt.close()\n",
        "    def test_data(self , batch_size = 1):\n",
        "        x_test = [] \n",
        "        img_path = '/content/drive/MyDrive/tech_project/imgs/'\n",
        "\n",
        "        all_files = os.listdir(img_path)\n",
        "        files = [item for item in all_files if \"img\" in item]\n",
        "        img_num = len(files)\n",
        "        for (n, file_name) in enumerate(files):\n",
        "            img = np.load(os.path.join(img_path,file_name))[:,:,0]\n",
        "            x_test.append(img)\n",
        "\n",
        "        x_test = np.expand_dims(np.array(x_test), axis=3) \n",
        "        \n",
        "        self.unet.load_weights(r\"weights/best_model.h5\")\n",
        "        # self.unet.load_weights(\"/content/drive/MyDrive/tech_project/model/1best_model.h5\")\n",
        "        test_num = x_test.shape[0]\n",
        "        index = 0\n",
        "        while index < test_num:\n",
        "            mask = self.unet.predict(x_test[index:index + batch_size]) > 0.5\n",
        "            mask = np.float32(mask[0, :, :, :])\n",
        "            np.save('/content/drive/MyDrive/tech_project/pred2/' + files[index].split('_')[0]+'_seg.npy',mask)\n",
        "            index += batch_size\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    model = U_Net()\n",
        "    model.train()    # start training\n",
        "    # model.test()     # 对图片进行分类验证\n",
        "    # model.test_random()    # 随机进行检测\n",
        "    # model.test_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvfJPTcJ4JJ6",
        "outputId": "b28e4c05-fcb3-408d-fe8d-425688eca460"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "finished epoch: 0\n",
            "finished epoch: 1\n",
            "finished epoch: 2\n",
            "finished epoch: 3\n",
            "finished epoch: 4\n"
          ]
        }
      ],
      "source": [
        "model.test_random()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "b2CDKAfyHiIx",
        "outputId": "3b52f1ef-fe89-44fd-ec51-6aaf1c75caea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1030, 1037, 3)\n",
            "(1030, 1037, 3)\n",
            "(1030, 1037, 3)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fbf90c7b350>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "img_2=cv2.imread('/content/evaluationow177_168_91.png')\n",
        "print(img_2.shape)\n",
        "img_3=cv2.imread('/content/evaluationow45_37_165.png')\n",
        "print(img_3.shape)\n",
        "img_4=cv2.imread('/content/evaluationow8_63_120.png')\n",
        "print(img_4.shape)\n",
        "# plt.imshow(img_2)\n",
        "# plt.imshow(img_3)\n",
        "plt.imshow(img_4,cmap='gray')\n",
        "# 自行去目录查看文件来源。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPRObErU_OtG"
      },
      "outputs": [],
      "source": [
        "def dice_score(self, y_true, y_pred):\n",
        "  predict = tf.reduce_sum(2 * y_true * tf.cast(tf.greater(y_pred, 0.1), tf.float32)) + 1e-8\n",
        "  validation = tf.reduce_sum(y_true + tf.cast(tf.greater(y_pred, 0.1), tf.float32)) + 1e-8\n",
        "  return predict / validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBg1yz--27lN"
      },
      "outputs": [],
      "source": [
        "x_test = []\n",
        "img_path = r'E:\\XJTLU\\IC\\0.5\\pred2'\n",
        "all_files = os.listdir(img_path)\n",
        "files = [item for item in all_files if \"seg\" in item]\n",
        "for (n, file_name) in enumerate(files):\n",
        "    img = np.load(os.path.join(img_path, file_name))\n",
        "    img = np.uint8(img)\n",
        "    np.save(os.path.join(img_path, file_name), img)\n",
        "# 讲文件转换为uint8格式"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
